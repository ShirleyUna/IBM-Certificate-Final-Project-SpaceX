{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork865-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones. \n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. \n",
    "\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch. \n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    " <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\" target=\"_blank\">Spacex DataSet</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Navigate to the Go to UI screen** \n",
    "\n",
    "* Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html\">link</a> for viewing  the   Go to UI screen. \n",
    "\n",
    "\n",
    "* Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.  \n",
    "\n",
    "\n",
    "\n",
    "* Later browse for the downloaded spacex file.\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\">\n",
    "\n",
    "\n",
    "* Once done select the schema andload the file.  \n",
    "\n",
    "\n",
    " <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\">\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "If you are facing a problem in uploading the dataset (which is a csv file), you can follow the steps below to upload the .sql file instead of the CSV file:\n",
    "\n",
    "* Download the file <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/Spacex%20.sql\">Spacex.sql</a>\n",
    "\n",
    "* Later click on **SQL** in the  **Go to UI Screen**.\n",
    "\n",
    "* Use the **From file** option to browse for the **SQL** file and upload it.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/sqlfile.png\">\n",
    "\n",
    "* Once you upload the script,you can use the **Run All** option to run all the queries to insert the data.\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/runall.png\">\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ibm_db==3.1.0\n",
      "  Downloading ibm_db-3.1.0.tar.gz (797 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.3/797.3 kB\u001b[0m \u001b[31m560.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting ibm_db_sa==0.3.3\n",
      "  Downloading ibm_db_sa-0.3.3.tar.gz (24 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sqlalchemy>=0.7.3\n",
      "  Downloading SQLAlchemy-2.0.8-cp39-cp39-macosx_10_9_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m350.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=4.2.0\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-2.0.2.tar.gz (164 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m409.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ibm_db, ibm_db_sa, greenlet\n",
      "  Building wheel for ibm_db (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm_db: filename=ibm_db-3.1.0-cp39-cp39-macosx_10_15_x86_64.whl size=32287120 sha256=58b97570a0ba16c971dfd73e899ee47cd4c1cc7be4a1247559840fba91105318\n",
      "  Stored in directory: /Users/shirleypgm/Library/Caches/pip/wheels/0a/dd/10/4a9ad59949e39786d729813e4bce24ccf2263c6d60a62de2f2\n",
      "  Building wheel for ibm_db_sa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm_db_sa: filename=ibm_db_sa-0.3.3-py3-none-any.whl size=27424 sha256=dc09e4e3f9c534016c67f0ac3cd697265fc924f63b22b643533f2697d0e28940\n",
      "  Stored in directory: /Users/shirleypgm/Library/Caches/pip/wheels/8f/98/0c/930c68279890092297e12d4cc20e95613ddab15af6753d92bb\n",
      "  Building wheel for greenlet (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for greenlet: filename=greenlet-2.0.2-cp39-cp39-macosx_10_9_x86_64.whl size=190761 sha256=6d1bc26fb480be934765ca94f9a11eac7b6cc90778e60c784aac13ecb9d143f1\n",
      "  Stored in directory: /Users/shirleypgm/Library/Caches/pip/wheels/c4/e2/38/932349e5e893e6d464ea70f98f76a8d7b9ba73e62cc9db5579\n",
      "Successfully built ibm_db ibm_db_sa greenlet\n",
      "Installing collected packages: ibm_db, typing-extensions, greenlet, sqlalchemy, ibm_db_sa\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 1.1.1\n",
      "    Uninstalling greenlet-1.1.1:\n",
      "      Successfully uninstalled greenlet-1.1.1\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.39\n",
      "    Uninstalling SQLAlchemy-1.4.39:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.39\n",
      "Successfully installed greenlet-2.0.2 ibm_db-3.1.0 ibm_db_sa-0.3.3 sqlalchemy-2.0.8 typing-extensions-4.5.0\n",
      "Collecting sqlalchemy==1.3.24\n",
      "  Downloading SQLAlchemy-1.3.24-cp39-cp39-macosx_10_14_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.8\n",
      "    Uninstalling SQLAlchemy-2.0.8:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.8\n",
      "Successfully installed sqlalchemy-1.3.24\n",
      "\u001b[33mWARNING: Skipping ipython-sql as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ipython-sql==0.4.1\n",
      "  Downloading ipython_sql-0.4.1-py3-none-any.whl (21 kB)\n",
      "Collecting sqlparse\n",
      "  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ipython>=1.0 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython-sql==0.4.1) (7.31.1)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython-sql==0.4.1) (0.2.0)\n",
      "Collecting prettytable<1\n",
      "  Downloading prettytable-0.7.2.zip (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sqlalchemy>=0.6.7 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython-sql==0.4.1) (1.3.24)\n",
      "Requirement already satisfied: six in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython-sql==0.4.1) (1.16.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (4.8.0)\n",
      "Requirement already satisfied: pygments in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (2.11.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.1.1)\n",
      "Requirement already satisfied: decorator in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (3.0.20)\n",
      "Requirement already satisfied: appnope in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (63.4.1)\n",
      "Requirement already satisfied: backcall in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.1.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from ipython>=1.0->ipython-sql==0.4.1) (0.18.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql==0.4.1) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql==0.4.1) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/shirleypgm/opt/anaconda3/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql==0.4.1) (0.2.5)\n",
      "Building wheels for collected packages: prettytable\n",
      "  Building wheel for prettytable (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prettytable: filename=prettytable-0.7.2-py3-none-any.whl size=13695 sha256=5af99ca4a5ca2a0079c6c66dd3ed1017e57915d3afa588fd217916a5fc9325ed\n",
      "  Stored in directory: /Users/shirleypgm/Library/Caches/pip/wheels/75/f7/28/77a076f1fa8cbeda61aca712815d04d7a32435f04a26a2dd7b\n",
      "Successfully built prettytable\n",
      "Installing collected packages: prettytable, sqlparse, ipython-sql\n",
      "Successfully installed ipython-sql-0.4.1 prettytable-0.7.2 sqlparse-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --force-reinstall ibm_db==3.1.0 ibm_db_sa==0.3.3\n",
    "!pip install sqlalchemy==1.3.24\n",
    "!pip uninstall ipython-sql -y\n",
    "!pip install ipython-sql==0.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**DB2 magic in case of  UI service credentials.**\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/servicecredentials.png\" width=\"600\">  \n",
    "\n",
    "* Use the following format.\n",
    "\n",
    "* Add security=SSL at the end\n",
    "\n",
    "**%sql ibm_db_sa://my-username:my-password@my-hostname:my-port/my-db-name?security=SSL**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ibm_db_sa://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection to postgreSQL database\n",
    "conn = psycopg2.connect(\n",
    "    host = 'localhost',\n",
    "    database = 'postgres', \n",
    "    user = 'postgres', \n",
    "    password = 'shirley',  \n",
    "    port = '8050')\n",
    "print('Connection successful')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read from database\n",
    "def read(conn, read_):\n",
    "    print('Read')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(read_)\n",
    "    for row in cursor:\n",
    "        print(f'row = {row}')\n",
    "    print()\n",
    "    \n",
    "# function to create in postgre database     \n",
    "def create(conn, create_):\n",
    "    cursor = conn.cursor() # create cursor object\n",
    "    cursor.execute(create_) # execute query\n",
    "    conn.commit() # commit query to database\n",
    "    print('Table have been created successfull!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to insert in postgre database     \n",
    "def insert(conn, insert_):\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(insert_)\n",
    "    conn.commit()\n",
    "    print('Records have been successfully inserted!!!')\n",
    "    #read(conn)\n",
    "    \n",
    "# function to update table\n",
    "def update(conn, update_):\n",
    "    print('Update')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(update_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "    \n",
    "# function to delete in postgre database\n",
    "def delete(conn, delete_):\n",
    "    print('Delete')\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(delete_)\n",
    "    conn.commit()\n",
    "    #read(conn)\n",
    "\n",
    "# close the cursor and connection to the server \n",
    "def close():\n",
    "    cursor.close()\n",
    "    conn.close()   \n",
    "    \n",
    "# function to create pandas dataframe\n",
    "def create_pandas_df(sql_query, database=conn):\n",
    "    table = pd.read_sql_query(sql_query, database)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data process\n",
    "### We have to create the table in the database using the CREATE function. Next we insert the csv file by loading the csv module. Then we would run the INSERT query for each row and then commit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table SpaceX\n",
    "create_ = '''\n",
    "            DROP TABLE IF EXISTS SpaceX;\n",
    "            CREATE TABLE SpaceX\n",
    "                (\n",
    "                    Date DATE NULL,\n",
    "                    Time TIME NULL,\n",
    "                    BoosterVersion VARCHAR(50) NULL,\n",
    "                    LaunchSite VARCHAR(50) NULL,\n",
    "                    Payload VARCHAR(100) NULL,\n",
    "                    PayloadMassKG INT NULL,\n",
    "                    Orbit VARCHAR(50) NULL,\n",
    "                    Customer VARCHAR(100) NULL,\n",
    "                    MissionOutcome VARCHAR(50) NULL,\n",
    "                    LandingOutcome VARCHAR(100) NULL\n",
    "                );\n",
    "            '''\n",
    "create(conn, create_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the csv file\n",
    "cursor = conn.cursor()\n",
    "with open('Spacex.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    next(reader) # Skip the header row.\n",
    "    for row in reader:\n",
    "        cursor.execute(\n",
    "        \"INSERT INTO SpaceX VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",\n",
    "        row\n",
    "    )\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read to see that data has been uploaded in database\n",
    "read_ = '''\n",
    "        SELECT *\n",
    "        FROM   SpaceX\n",
    "        LIMIT 10\n",
    "        '''\n",
    "read(conn, read_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output postgre query in pandas dataframe\n",
    "spacex = create_pandas_df(read_, database=conn)\n",
    "spacex.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "### Task 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1 = '''\n",
    "        SELECT DISTINCT LaunchSite \n",
    "        FROM SpaceX\n",
    "'''\n",
    "create_pandas_df(task_1, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2\n",
    "\n",
    "\n",
    "#####  Display 5 records where launch sites begin with the string 'CCA' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_2 = '''\n",
    "        SELECT *\n",
    "        FROM SpaceX\n",
    "        WHERE LaunchSite LIKE 'CCA%'\n",
    "        LIMIT 5\n",
    "        '''\n",
    "create_pandas_df(task_2, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_3 = '''\n",
    "        SELECT SUM(PayloadMassKG) AS Total_PayloadMass\n",
    "        FROM SpaceX\n",
    "        WHERE Customer LIKE 'NASA (CRS)'\n",
    "        '''\n",
    "create_pandas_df(task_3, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_4 = '''\n",
    "        SELECT AVG(PayloadMassKG) AS Avg_PayloadMass\n",
    "        FROM SpaceX\n",
    "        WHERE BoosterVersion = 'F9 v1.1'\n",
    "        '''\n",
    "create_pandas_df(task_4, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date when the first successful landing outcome in ground pad was acheived.\n",
    "\n",
    "\n",
    "_Hint:Use min function_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_5 = '''\n",
    "        SELECT MIN(Date) AS FirstSuccessfull_landing_date\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome LIKE 'Success (ground pad)'\n",
    "        '''\n",
    "create_pandas_df(task_5, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_6 = '''\n",
    "        SELECT BoosterVersion\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome = 'Success (drone ship)'\n",
    "            AND PayloadMassKG > 4000 \n",
    "            AND PayloadMassKG < 6000\n",
    "        '''\n",
    "create_pandas_df(task_6, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_7a = '''\n",
    "        SELECT COUNT(MissionOutcome) AS SuccessOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE MissionOutcome LIKE 'Success%'\n",
    "        '''\n",
    "\n",
    "task_7b = '''\n",
    "        SELECT COUNT(MissionOutcome) AS FailureOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE MissionOutcome LIKE 'Failure%'\n",
    "        '''\n",
    "print('The total number of successful mission outcome is:')\n",
    "display(create_pandas_df(task_7a, database=conn))\n",
    "print()\n",
    "print('The total number of failed mission outcome is:')\n",
    "create_pandas_df(task_7b, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "\n",
    "\n",
    "##### List the   names of the booster_versions which have carried the maximum payload mass. Use a subquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_8 = '''\n",
    "        SELECT BoosterVersion, PayloadMassKG\n",
    "        FROM SpaceX\n",
    "        WHERE PayloadMassKG = (\n",
    "                                SELECT MAX(PayloadMassKG)\n",
    "                                FROM SpaceX\n",
    "                                )\n",
    "        ORDER BY BoosterVersion\n",
    "        '''\n",
    "create_pandas_df(task_8, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "\n",
    "##### List the failed landing_outcomes in drone ship, their booster versions, and launch site names for in year 2015\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_9 = '''\n",
    "        SELECT BoosterVersion, LaunchSite, LandingOutcome\n",
    "        FROM SpaceX\n",
    "        WHERE LandingOutcome LIKE 'Failure (drone ship)'\n",
    "            AND Date BETWEEN '2015-01-01' AND '2015-12-31'\n",
    "        '''\n",
    "create_pandas_df(task_9, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_10 = '''\n",
    "        SELECT LandingOutcome, COUNT(LandingOutcome)\n",
    "        FROM SpaceX\n",
    "        WHERE DATE BETWEEN '2010-06-04' AND '2017-03-20'\n",
    "        GROUP BY LandingOutcome\n",
    "        ORDER BY COUNT(LandingOutcome) DESC\n",
    "        '''\n",
    "create_pandas_df(task_10, database=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "* <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>  \n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*  <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb\">Hands-on Lab: Analyzing a real World Data Set</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change log\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|------|--------|--------|---------|\n",
    "| 2021-10-12 | 0.4 |Lakshmi Holla | Changed markdown|\n",
    "| 2021-08-24 | 0.3 |Lakshmi Holla | Added library update|\n",
    "| 2021-07-09 | 0.2 |Lakshmi Holla | Changes made in magic sql|\n",
    "| 2021-05-20 | 0.1 |Lakshmi Holla | Created Initial Version |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
